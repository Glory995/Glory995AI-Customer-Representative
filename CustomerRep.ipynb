{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7abf28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import openai \n",
    "import os  \n",
    "\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2bdcc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key: sk-or-v1-5 ...\n",
      "Base URL: https://openrouter.ai/api/v1/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=os.getenv(\"OPENROUTER_API_BASE\")\n",
    ")\n",
    "\n",
    "print(\"API Key:\", client.api_key[:10], \"...\")\n",
    "print(\"Base URL:\", client.base_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126e70ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API Call Successful!\n",
      "Hello! Iâ€™m an AI language model created by OpenAI. My purpose is to assist with answering questions, explaining concepts, generating ideas, writing content, and much more. I donâ€™t have personal experiences or consciousness, but Iâ€™m here to provide helpful and accurate information based on the data Iâ€™ve been trained on. Feel free to ask me anythingâ€”Iâ€™m here to help! ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek/deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello AI, please introduce yourself\"}\n",
    "    ],\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f58be083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI's Answer:\n",
      "Python is a high-level, interpreted programming language known for its simplicity, readability, and versatility, making it suitable for a wide range of applications from web development to data science and artificial intelligence.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek/deepseek-chat\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is Python in one sentence?\"}],\n",
    "    max_tokens=500\n",
    "\n",
    ")\n",
    "\n",
    "ai_text = response.choices[0].message.content \n",
    "\n",
    "\n",
    "print(\"\\nAI's Answer:\")\n",
    "print(ai_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc557a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The question used: 10 tokens\n",
      "  AI's response used: 39 tokens\n",
      "  Total tokens billed: 49 tokens\n",
      "\n",
      " Cost Breakdown for This Call:\n",
      "  Input cost:  $0.000008 (10 tokens)\n",
      "  Output cost: $0.000125 (39 tokens)\n",
      "  TOTAL COST:  $0.000133\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Tokens are like \"pieces of words\" that AI uses:\n",
    "# - Simple words = 1 token (e.g., \"cat\", \"run\")\n",
    "# - Complex words = multiple tokens (e.g., \"unbelievable\" = 3 tokens)\n",
    "# - Rough estimate: 1 token â‰ˆ 4 characters or 0.75 words\n",
    "\n",
    " \n",
    "#  response.usage                      \n",
    "#  â”œâ”€â”€ prompt_tokens      (input)    \n",
    "#  â”œâ”€â”€ completion_tokens  (output)   \n",
    "#  â””â”€â”€ total_tokens       (sum)      \n",
    "\n",
    "input_tokens = response.usage.prompt_tokens  \n",
    "output_tokens = response.usage.completion_tokens  \n",
    "total_tokens = response.usage.total_tokens    \n",
    "\n",
    "\n",
    "print(f\"  The question used: {input_tokens} tokens\")\n",
    "print(f\"  AI's response used: {output_tokens} tokens\")\n",
    "print(f\"  Total tokens billed: {total_tokens} tokens\")\n",
    "\n",
    "\n",
    "\n",
    "# CALCULATING REAL BUSINESS COSTS\n",
    "# Output costs 4x more than input!\n",
    "# This is why keeping AI responses concise matters for your budget.\n",
    "\n",
    "\n",
    "# Let assume this is the price for 1000 token for our model \n",
    "input_price_per_1k = 0.0008   \n",
    "output_price_per_1k = 0.0032  \n",
    "\n",
    "\n",
    "input_cost = (input_tokens / 1000) * input_price_per_1k\n",
    "output_cost = (output_tokens / 1000) * output_price_per_1k\n",
    "total_cost = input_cost + output_cost\n",
    "\n",
    "print(\"\\n Cost Breakdown for This Call:\")\n",
    "print(f\"  Input cost:  ${input_cost:.6f} ({input_tokens} tokens)\")\n",
    "print(f\"  Output cost: ${output_cost:.6f} ({output_tokens} tokens)\")\n",
    "print(f\"  TOTAL COST:  ${total_cost:.6f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99ea752",
   "metadata": {},
   "source": [
    "## LangChain\n",
    "\n",
    "10+ lines of boilerplate. Want to switch to Google? Rewrite everything! brahhhhhh thanks to langChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd2f2db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Client Calling : Machine learning is a subset of artificial intelligence that enables systems to automatically learn ...\n",
      "Langhain Response result : Machine learning is the field of study that enables computers to learn from data and improve their p...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "def raw_openai_approach():\n",
    "    \n",
    "    import openai\n",
    "\n",
    "    client = openai.OpenAI(\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=os.getenv(\"OPENROUTER_API_BASE\")\n",
    ")\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"deepseek/deepseek-chat\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Explain machine learning in one sentence\"}],\n",
    "    max_tokens=500\n",
    "\n",
    ")\n",
    "\n",
    "    if response:\n",
    "        text = response.choices[0].message.content \n",
    "        print(f\"Normal Client Calling : {text[:100]}...\")\n",
    "        return text\n",
    "\n",
    "    return None\n",
    "\n",
    "def langchain_approach():\n",
    "    from langchain_openai import ChatOpenAI\n",
    "\n",
    "    \n",
    "    llm = ChatOpenAI(\n",
    "        model=\"deepseek/deepseek-chat\",                    \n",
    "        api_key=os.getenv(\"OPENROUTER_API_KEY\"),      \n",
    "        base_url=os.getenv(\"OPENROUTER_API_BASE\"),      \n",
    "        max_tokens=500, \n",
    "    )\n",
    "\n",
    "    \n",
    "    response = llm.invoke(\"Explain machine learning in one sentence\")  \n",
    "\n",
    "    if response:\n",
    "        print(f\"Langhain Response result : {response.content[:100]}...\")\n",
    "        return response.content\n",
    "\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "     \n",
    "    raw_openai_approach()\n",
    "    langchain_approach()\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849a4428",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
